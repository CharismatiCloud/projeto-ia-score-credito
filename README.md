# InteligÃªncia Artificial: PrevisÃ£o de Score de CrÃ©dito ğŸ§ ğŸ’³

Este projeto utiliza Machine Learning para automatizar a anÃ¡lise de perfil de crÃ©dito de clientes. O objetivo Ã© classificar novos clientes em trÃªs categorias de score (Good, Standard, Poor), auxiliando instituiÃ§Ãµes financeiras na tomada de decisÃ£o sobre concessÃ£o de crÃ©dito.

## ğŸ“ Estrutura de Arquivos
- `main.ipynb`: Jupyter Notebook com todo o pipeline de dados (limpeza, codificaÃ§Ã£o e treinamento).
- `clientes.csv`: Base de dados histÃ³rica usada para o treinamento dos modelos.
- `novos_clientes.csv`: Base de dados de novos clientes usada para realizar as previsÃµes finais.

## ğŸ› ï¸ Tecnologias e Bibliotecas
- **Python 3**
- **Pandas**: Para manipulaÃ§Ã£o e anÃ¡lise exploratÃ³ria de dados.
- **Scikit-Learn (Sklearn)**: Para a implementaÃ§Ã£o dos algoritmos de Machine Learning e mÃ©tricas de avaliaÃ§Ã£o.

## ğŸ¤– Fluxo de Desenvolvimento
1. **PrÃ©-processamento (Data Cleaning)**: IdentificaÃ§Ã£o e tratamento de colunas nÃ£o numÃ©ricas que precisam ser convertidas para que a IA processe a informaÃ§Ã£o.
2. **Label Encoding**: Uso do `LabelEncoder` para transformar categorias (como ProfissÃ£o e Mix de CrÃ©dito) em valores numÃ©ricos.
3. **DivisÃ£o de Dados**: SeparaÃ§Ã£o da base em conjuntos de **Treino** (80%) e **Teste** (20%).
4. **Treinamento de Modelos**: Foram treinados dois algoritmos principais:
   - **Random Forest (Ãrvore de DecisÃ£o)**
   - **KNN (K-Nearest Neighbors)**
5. **AvaliaÃ§Ã£o**: ComparaÃ§Ã£o da acurÃ¡cia de cada modelo para definir o mais eficaz.



## ğŸ“Š Performance dos Modelos
ApÃ³s os testes, o modelo de **Random Forest** demonstrou maior precisÃ£o na classificaÃ§Ã£o dos perfis de crÃ©dito, sendo escolhido para realizar as previsÃµes na base de `novos_clientes.csv`.

## âš™ï¸ Como Executar
1. Certifique-se de ter as bases `.csv` na mesma pasta do cÃ³digo.
2. Instale as dependÃªncias:
   ```bash
   pip install pandas scikit-learn
3. Execute o arquivo main.ipynb utilizando Jupyter ou VS Code.
Projeto desenvolvido durante a Jornada Python da Hashtag Treinamentos.
